{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import json"
      ],
      "metadata": {
        "id": "8NduCPYd0J7l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat model Keras\n",
        "model = tf.keras.models.load_model('model_nextStep.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeLbGxXl6ezI",
        "outputId": "c4149c30-853f-4552-cbdb-55beb884ba7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**dengan .json**"
      ],
      "metadata": {
        "id": "2_9ZVOZdjIxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat tokenizer dan label pekerjaan dari file JSON\n",
        "with open('tokenizer_and_labels.json', 'r') as f:\n",
        "    tokenizer_data = json.load(f)  # Membaca JSON dari file dan memuat sebagai dictionary\n",
        "\n",
        "# Konversi dictionary tokenizer ke string JSON\n",
        "tokenizer_json = json.dumps(tokenizer_data)\n",
        "\n",
        "# Memuat tokenizer dari string JSON\n",
        "tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_json)\n",
        "\n",
        "# Memuat label pekerjaan\n",
        "y_titles = tokenizer_data.get('job_titles', {})\n",
        "index_to_job_title = {index: title for title, index in y_titles.items()}\n",
        "\n",
        "# Contoh penggunaan\n",
        "print(\"Tokenizer dan label pekerjaan berhasil dimuat.\")\n",
        "print(f\"Total job titles: {len(index_to_job_title)}\")"
      ],
      "metadata": {
        "id": "xtSB-xPcWZxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ebd0b8-d7b3-4157-a4db-748c75d69af8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer dan label pekerjaan berhasil dimuat.\n",
            "Total job titles: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk prediksi\n",
        "def predict_top_jobs(skills, label_map, top_n=3):\n",
        "    \"\"\"\n",
        "    Melakukan prediksi job title berdasarkan keterampilan yang diberikan.\n",
        "\n",
        "    Args:\n",
        "        skills (list): Daftar keterampilan user.\n",
        "\n",
        "    Returns:\n",
        "        list: Job titles yang paling relevan.\n",
        "    \"\"\"\n",
        "    # Mengubah keterampilan ke representasi one-hot menggunakan tokenizer\n",
        "    skills_encoded = tokenizer.texts_to_matrix([' '.join(skills)], mode='binary')\n",
        "\n",
        "    # Membuat prediksi\n",
        "    predictions = model.predict(skills_encoded)\n",
        "    # predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "    # Ambil indeks dan probabilitas dari prediksi tertinggi\n",
        "    top_indices = np.argsort(predictions[0])[::-1][:top_n]  # Urutkan secara descending dan ambil top_n\n",
        "    top_jobs = [(label_map[idx], predictions[0][idx]) for idx in top_indices]\n",
        "\n",
        "    return top_jobs"
      ],
      "metadata": {
        "id": "fylxrfsjhL1n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh input keterampilan\n",
        "sample_skills = ['CyberSecurity']  # Contoh keterampilan untuk prediksi\n",
        "top_jobs = predict_top_jobs(sample_skills, index_to_job_title, top_n=3)\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "print(\"Top 3 Predicted Job Titles:\")\n",
        "for i, (job_title, probability) in enumerate(top_jobs, start=1):\n",
        "    print(f\"{i}. {job_title}\")# (Probability: {probability:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ3MRr21hMY_",
        "outputId": "9042c9c7-6e34-49b1-8c54-f6e893601fd9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Top 3 Predicted Job Titles:\n",
            "1. Cybersecurity Analyst\n",
            "2. AI Ethics Consultant\n",
            "3. IT Support Specialist\n"
          ]
        }
      ]
    }
  ]
}